üí° ÂÆûÁé∞ÊñπÂºèÁõ∏ÂÖ≥
Why did you choose to use ExpandedObjectHeader instead of a lighter struct or native C struct for in-memory layout?
‚Üí ÊÉ≥‰∫ÜËß£‰ΩøÁî® PostgreSQL ÂÜÖÈÉ®ÁöÑ expanded object API ËÄå‰∏çÊòØËá™ÂÆö‰πâÁªìÊûÑÁöÑÂéüÂõ†ÔºåÊòØ‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞ÈõÜÊàê PG ÂÜÖÊ†∏ÔºåËøòÊòØ‰∏∫‰∫ÜÂÆûÁé∞ flatten/expandÔºü
What are the design tradeoffs between using uthash versus using PostgreSQL‚Äôs own hash table infrastructure (e.g., dynahash)?
‚Üí uthash ÊòØËΩªÈáè‰ΩÜÊ≤°ÊúâÂÜÖÂª∫ÁöÑ memory context ÊîØÊåÅÔºåPG ÂÜÖÁΩÆÁöÑ hash table ÂèØËÉΩÈõÜÊàêÊõ¥Á¥ßÂØÜ„ÄÇ
Is it safe to use a collection type as a field in composite types or pass between functions that cross memory contexts?
‚Üí ÂΩìÂâç memory context ÈöîÁ¶ªÁ≠ñÁï•ÊòØÂê¶ÂÖÅËÆ∏Ë∑®ÂáΩÊï∞ÂÆâÂÖ®‰ΩøÁî®Ôºåflatten ÊòØÂê¶ÊòØÂøÖË¶ÅÊ≠•È™§Ôºü
Why limit to only text as key? Any plans to support other key types like int or uuid in the future?
‚Üí ÁõÆÂâçÂè™ÊîØÊåÅ text Á±ªÂûã keyÔºå‰ΩÜÂÆûÈôÖ‰∏öÂä°‰∏≠Â∏∏ËßÅ int/uuid ‰Ωú‰∏∫‰∏ªÈîÆ„ÄÇ
Why isn't there support for nested collections (collections inside collections)?
‚Üí ÊòØÂê¶ÊúâËÆæËÆ°ÈôêÂà∂ÔºåÊàñÂè™ÊòØ v1 Â∞öÊú™ÊîØÊåÅÔºüÊòØÂê¶ÊúâËÆ°ÂàíÂÆûÁé∞Á±ª‰ººÂµåÂ•ó map ÁªìÊûÑÔºü



What are the advantages of pgcollection over JSON?
1. Strongly typed values
Unlike JSON, which stores data as untyped strings or loosely structured objects, pgcollection enforces a consistent data type for all values. When you create a collection, you can define that all values must be text, integer, date, or even complex types like record. This helps catch type errors early and allows PostgreSQL to optimize memory and operations more efficiently.

2. Fast key-based access (O(1) vs. linear search)
pgcollection uses an internal hash table (via uthash) to store and retrieve key-value pairs. This means accessing a value by key takes constant time, regardless of the size of the collection. In contrast, accessing a value in a JSON object within PL/pgSQL often involves parsing the entire structure and doing a linear scan, which becomes slower as the JSON grows.

3. Optimized for in-memory usage
pgcollection is designed for temporary, high-speed operations inside functions, especially in PL/pgSQL. All data lives in memory and never touches disk unless explicitly saved. This makes it ideal for use cases like caching, aggregation, or building intermediate results during a complex computation.

4. Native subscript syntax
Accessing elements in a collection is straightforward and readable: collection['key'] := 'value'; or collection['key']. There‚Äôs no need to cast or extract from a JSON blob using functions like ->> or jsonb_extract_path_text(). This syntax improves developer productivity and clarity.

5. Built-in iteration tools
pgcollection supports iterators like first(), next(), key(), and value() to loop over elements in order. This is more natural and efficient than trying to unpack and traverse a JSON structure inside a PL/pgSQL loop. You don‚Äôt need to call jsonb_each() or convert JSON into a temporary table ‚Äî pgcollection provides direct, in-memory iteration.


How pgcollection really aligns (or not) with Oracle collection kinds
Aspect	Oracle‚ÄØVARRAY / Nested‚Äëtable	Oracle‚ÄØAssociative‚ÄØarray	pgcollection reality
Bounded vs. unbounded	VARRAY is bounded‚ÄØ; Nested‚Äëtable is unbounded	Unbounded	Unbounded until memory (or 1‚ÄØGB when flattened to disk) exhausts ‚Äì so this matches Nested‚Äëtable/associative array behaviour.
Index/key type	VARRAY/Nested‚Äëtable use integer subscripts starting at‚ÄØ1	Can be integer or string	Currently only text keys. You cannot use an integer subscript unless you cast it to text. Future work could add an integer path, but today it is string‚Äëonly.
Sparsity	VARRAY dense, Nested‚Äëtable can be sparse after DELETE	Associative arrays can be sparse	pgcollection is hash‚Äëbased and therefore naturally sparse. Keys are not required to be contiguous or sequential.
On‚Äëdisk persistence	Nested‚Äëtable/ VARRAY columns stored as separate child tables or LOBs, support indexing and query	Associative array cannot be stored in a column	pgcollection can be stored in a column, but as a single varlena blob (max 1‚ÄØGB) ‚Äì there is no child table, no column‚Äëlevel indexing, and the server must fully expand the blob to query it. So it is persistible like a nested table but without relational visibility or indexes.
Ordering semantics	VARRAY keeps positional order; Nested‚Äëtable loses order unless you ORDER BY; Associative array order undefined	pgcollection preserves insertion order until you call sort().	
Key take‚Äëaways
Index datatype is indeed only text today.
All subscripts are stored as strings; an integer must be cast (add(c, '42', 'val')). So your second bullet is correct.
Persistence is not the same as Oracle nested‚Äëtable storage.
When you put a collection in a column, PostgreSQL stores it as an opaque varlena; you cannot join to it or index inside it without expanding it in every query. Oracle nested tables, by contrast, become real child tables that can be indexed and queried directly.
Hybrid but closer to an associative array.
Because keys are hash‚Äëbased strings, and because the structure is sparse and unbounded, pgcollection behaves more like Oracle‚Äôs associative array than like a nested table‚Äîin spite of its ability to be stored on disk. The absence of integer subscripts and relational indexing makes it less like a true nested‚Äëtable implementation.



pgcollection already delivers a fast, string‚Äëkey associative map, yet several corners of the current design differ from what developers expect after years with Oracle collections. Bringing the extension closer to that mental model mainly involves widening its type system, smoothing high‚Äëvolume workflows, and adding guard‚Äërails against accidental or hostile misuse.

First, every subscript is coerced to text during parse analysis, so an integer key has to be cast to a string on every call. In Oracle an associative array may be indexed by either a number or a string, and code often chooses numbers when modelling lists. Introducing an alternate typemod‚Äîsay collection_int_key‚Äîwould let the subscript transformer accept int4 directly, store the binary integer in a parallel hash path, and expose bidirectional casts in the I/O routines. This change removes per‚Äëcall casts and allows the planner to use an ordinary equality operator when comparing keys typed as integers.

At the moment the only bulk constructor is a JSON blob that users must hand‚Äëcraft. Oracle developers are accustomed to literal constructors such as address_list_type(address_type(...), ‚Ä¶) in SQL and PL/SQL. Exposing wrapper functions like collection_from_json(json) and, even more user‚Äëfriendly, a variadic collection_lit(VARIADIC "any") that accepts alternating key‚Äìvalue arguments, would reduce the boilerplate of add() loops and eliminate the temptation to slip procedural code into pure SQL.

Nested collections are another gap. Oracle permits a nested table to contain another collection to a reasonable depth (three levels is common). In pgcollection any attempt to store a collection as a value fails type‚Äëchecking. Because the flatten/expand logic is already recursive over values of varying length, enabling collection‚Äëof‚Äëcollection is mainly a matter of allowing value_type to reference the collection OID and descending into the inner header during serialization. A safety GUC limiting maximum nesting depth prevents runaway recursion.

Insertion order versus sorted order is a frequent pain‚Äëpoint. Many Oracle codes rely on VARRAY position or explicitly sorted associative arrays. Pgcollection lets you call sort(c) after bulk load, but that triggers an additional full pass and shows up as CollectionSort waits. A typemod flag such as collection('text' SORTED) could instruct add() to binary‚Äësearch the hash‚Äôs ordered list and insert keys at the correct position, making subsequent iteration ordered without the extra pass.

Stability under hostile input needs work. Flattening more than one gigabyte of data causes the varlena allocator to fail, taking out the backend. The size is already computed in collection_get_flat_size; a single if (sz > MaxCollectionBytes) ereport(ERROR, ...) would convert a hard crash into a polite exception. Likewise, optional GUCs collection_max_elements and collection_max_bytes would let DBAs cap memory use per backend before an attacker or runaway job exhausts RAM.

Query users sometimes prefer streaming large collections via cursors instead of materialising them entirely. Because to_table(c) currently expands the whole set in one step, a new SRF such as collection_stream(c, batch_size int) could yield rows in blocks, maintaining internal iteration state and emitting the next slice only when the caller fetches again. That mirrors Oracle‚Äôs open‚Äëcursor‚Äëover‚ÄëTABLE(nested_collection) pattern and keeps memory consumption flat.

The value path could be tightened as well. If callers declare value_type = jsonb, there is no reason to convert each element to text when writing collection_out. Copying the binary jsonb datum directly into the output buffer would avoid an extra parse/stringify cycle and shrink output size. Extending the value‚Äêtype dispatch table to treat varlena values with TYPCATEGORY_JSON specially is enough to achieve this optimisation.

A subtle behavioural quirk is that c[NULL] returns the ‚Äúcurrent‚Äù iterator position, emulating Oracle‚Äôs default when the index is omitted. While useful, the behaviour surprises new users who expect a NULL subscript to throw. A GUC such as collection.null_subscript_error = on could toggle between permissive and strict modes, giving teams the choice of Oracle compatibility or defensive programming.

Finally, collection_cast() merely verifies that the stored value type can be implicitly coerced to the requested typmod; it does not rewrite existing elements. Applications could mis‚Äëcast a text collection to int4 and only hit conversion failures later. Offering a collection_cast_strict(c, 'int4') that attempts to convert every element in place‚Äîand fails early if one element is invalid‚Äîwould close that loophole.

Implementing even a subset of these enhancements‚Äîsize guardrail, integer subscripts, exposed JSON/variadic constructors, and strict cast mode‚Äîwould eliminate the most acute surprises, align pgcollection with Oracle semantics, and make the extension safer and easier to adopt in mixed‚Äëworkload environments.
